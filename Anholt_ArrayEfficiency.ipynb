{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWA Anholt Array Efficiency: Benchmark Evaluation Script\n",
    "*Javier Sanz Rodrigo, Fernando Borb√≥n, Pedro Miguel Fernandes Correia, Pawel Gancarski (CENER)* \n",
    "\n",
    "*February 2019*\n",
    "\n",
    "## Introduction\n",
    "This is the model evaluation script for the [OWA-Anholt Array Efficiency benchmark](https://thewindvaneblog.com/the-owa-anholt-array-efficiency-benchmark-436fc538597d) as part of the [OWA Wake Modeling Challenge](https://www.carbontrust.com/media/677495/owa-wake-modelling-challenge_final-feb27.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations\n",
    "The following models participate in the benchmark.\n",
    "\n",
    "**Table 1. Participating models.**\n",
    "\n",
    "| simID | Participant | Model Name | Model Type | Approach | Remarks | \n",
    "| :---  | :---:       | :---:      | :---:      | :---:    | ---     |\n",
    "| anh01 | ProPlanEn | WakeBlaster | RANS Eddy-Viscosity | time series  | - | \n",
    "| anh02 | TU-Delft | eWakeLab | PARK | time series | $$ C_{w} = 0.05 $$ |\n",
    "| anh03 | Anonymous | Anonymous | Engineering | time series | - |\n",
    "| anh04 | Anonymous | Anonymous | Engineering | time series | - |\n",
    "| anh05 | EMD | WindPro | PARK2 | time series | stability based |\n",
    "| anh06 | EMD | WindPro | PARK2 | time series | TI based | \n",
    "| anh07 | IFPEN | FarmShadow | Ishihara&Qian |bin-averages | uniform inflow | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id =    ['anh01','anh02','anh03','anh04','anh05','anh06','anh07']\n",
    "sim_name = ['WakeBlaster_ProPlanEn','PARK_TUD','anh03','anh04','PARK2stab_EMD','PARK2ti_EMD','FarmShadow_IFPEN']\n",
    "sim_model = ['RANS-EV'  ,'ENG' ,'ENG'  ,'ENG' ,'ENG'  ,'ENG'  , 'ENG']\n",
    "sim_type =  ['ts'   ,'ts'   ,'ts'   ,'ts'   ,'ts'   , 'ts', 'ba'   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from src.WindConditions import *\n",
    "from src.BinAvrg import *  \n",
    "from scipy import interpolate\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind farm input data \n",
    "The scada_flags dataframe indicates which timestamps have been filtered out in the quality-control process of the SCADA data. This allows to perform the evaluation on validation dataset which only contains situations where the wind farm is operating in normal conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./inputs/Anholt_pwc.csv' does not exist: b'./inputs/Anholt_pwc.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e400f63f6a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load manufacturer's power curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpwr_curve_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./inputs/Anholt_pwc.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpwr_curve_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpwr_curve_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'power'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;31m# scale to MW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m pwr_curve = interpolate.interp1d(pwr_curve_file['U'].values.flatten(),pwr_curve_file['power'].values.flatten(), \n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./inputs/Anholt_pwc.csv' does not exist: b'./inputs/Anholt_pwc.csv'"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "datefrom = time_stamp(2013,1,1,0,0,0)    # evaluation period\n",
    "dateto = time_stamp(2015,6,30,23,0,0)    # evaluation period\n",
    "\n",
    "siteID = 'Anholt'\n",
    "Hhub = 81.6         # hub-height\n",
    "Drot = 120          # rotor diameter\n",
    "lat_ref = 56.6      # degrees N \n",
    "lon_ref = 11.2      # degrees E\n",
    "\n",
    "# Load manufacturer's power curve \n",
    "pwr_curve_file = pd.read_csv('./inputs/Anholt_pwc.csv', sep = ';')\n",
    "pwr_curve_file['power'] = pwr_curve_file['power']/1000 # scale to MW\n",
    "pwr_curve = interpolate.interp1d(pwr_curve_file['U'].values.flatten(),pwr_curve_file['power'].values.flatten(), \n",
    "                                bounds_error = False, fill_value = 0)\n",
    "# when converting power to speed use the rev_pwr_curve\n",
    "###rev_pwr_curve = interpolate.interp1d(pwr_curve_file['power'].values.flatten(),pwr_curve_file['U'].values.flatten())\n",
    "\n",
    "# Load wind farm layout data\n",
    "turbines = pd.read_csv(\"inputs/Anholt_layout.csv\")\n",
    "plot_wf_layout(turbines['X coordinate'], turbines['Y coordinate'],labels = turbines['VDC ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data availability flags\n",
    "This file is provided to the participants so they can compute their bin-averages using the same timestamps of the validation data. Notice that:\n",
    "\n",
    "* $min\\_data\\_availability$ sets the minimum availability of original (non-reconstructed) observational data, i.e. for 90%, no more than 10% is reconstructed.\n",
    "\n",
    "* $scada\\_ts$ list the time stamps that will be retained in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scada_flags = pd.read_csv('./inputs/obs_flags.csv', index_col = 'time') \n",
    "min_data_availability = 90 # minimum data availability in %\n",
    "scada_ts = flags_to_ts(scada_flags, min_data_availability) # generate a list of accepted time series\n",
    "\n",
    "print(\"Hence, after applying the filter we get %d hourly samples, which is %.2f%% of the original data\" % (scada_ts.shape[0],scada_ts.shape[0]*100/scada_flags.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind conditions from mesoscale input data\n",
    "In the absence of an *undisturbed* met mast, the wind farm centroid is used as reference site to define wind conditions and classify the wind climate in terms of wind direction sectors and stability classes. This site has also been used as the center of the innermost domain in the WRF set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins to classify wind conditions \n",
    "Sbins = np.array([8,10])              # around the maximum of the trust coefficient \n",
    "WDbins = np.arange(-15.,360.+15.,30)  # wind direction bins (12 sectors)\n",
    "WDbins_label = ['N','NNE','ENE','E','ESE','SSE',\n",
    "                'S','SSW','WSW','W','WNW','NNW']\n",
    "zLbins = [-0.2,-0.02, 0.02, 0.2]      # 3 stability bins\n",
    "zLbins_label = ['u','n','s']\n",
    "\n",
    "# interpolate to reference height\n",
    "zref = Hhub         # [m]\n",
    "\n",
    "# Load mesoscale data from the referent site (time-height profiles)\n",
    "mast = WindConditions('./inputs/Anholt_Lav30km_ref.nc',lat_ref, lon_ref, siteID, datefrom, dateto)\n",
    "\n",
    "#init the bin averaging class\n",
    "bin_avrg = BinAvrg(siteID,datefrom, dateto, WDbins, WDbins_label, zLbins, zLbins_label,turbines['VDC ID'],sim_id)\n",
    "\n",
    "#filter for wind speed bin\n",
    "scada_ts = bin_avrg.filter_s(mast, zref, scada_ts, Sbins)\n",
    "\n",
    "# Compute and plot distributions \n",
    "N_WDzL_all,_,_,_,_ = mast.plot_stability(WDbins,WDbins_label,zLbins,zLbins_label,zref)\n",
    "\n",
    "# after filtering\n",
    "mast.reduce_to_ts(scada_ts)\n",
    "N_WDzL_speed,_,_,_,_ = mast.plot_stability(WDbins,WDbins_label,zLbins,zLbins_label,zref)\n",
    "\n",
    "figcaption = (\"**Fig 1. Distributions at zref for all data (above) and retained for validation (below)**\")\n",
    "display(Markdown(figcaption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hence, after filtering for the wind speed, stability and direction bins, there are %d hourly samples (%.2f%% of the original data) distributed according to the following validation bins:\" % (N_WDzL_speed.sum().sum(), N_WDzL_speed.sum().sum()*100/scada_flags.shape[0]))\n",
    "N_WDzL_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the mesoscale data interpolated at the turbine positions to generate reference power data that will be used in the definition of array efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mesoscale data at turbine positions (time-series at hub-height)\n",
    "f = netCDF4.Dataset('./inputs/Anholt_WindTurbines.nc', 'r')\n",
    "meso_ts_windspeed = pd.DataFrame(\n",
    "            (f.variables['U'][:].data**2 + f.variables['V'][:].data**2)**0.5, \n",
    "            index = f.variables['Times'][:].data)\n",
    "meso_ts_windspeed = restrict_to_ts(meso_ts_windspeed, scada_ts)\n",
    "\n",
    "meso_ts_power = meso_ts_windspeed.transform(pwr_curve) # convert to power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mapping of time stamps per wind direction and stability bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping, \n",
    "ts_bin_map = bin_avrg.create_ts_to_bin_map(mast, zref, scada_ts)\n",
    "# where ts_bin_map[0][0] provides indices to samples in the N-u bin  \n",
    "\n",
    "# Compute bin-averaged (and std) quantities,\n",
    "meso_P, meso_P_std = bin_avrg.compute_mean(meso_ts_power, ts_bin_map)\n",
    "# where a 3D array is created, e.g. meso_p.loc['ANHA01'].loc['N'].loc['u'] provides the mean power at \n",
    "# turbine A01 for North sector in unstable conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the submitted simulation data files and categorize them according to Table 1\n",
    "n_sim = len(sim_id)\n",
    "sim_ts = []\n",
    "sim_P = bin_avrg.array_init(('sim', 'wt','wd','zL'))\n",
    "sim_P_std = bin_avrg.array_init(('sim', 'wt','wd','zL'))\n",
    "\n",
    "for isim in range(0,n_sim):\n",
    "    file_name = './outputs/'+ sim_id[isim] +'.csv'\n",
    "    ts = p = p_std = None\n",
    "    if sim_type[isim] == 'ts': \n",
    "        ts = pd.read_csv(file_name, index_col = 'time')  # read .csv output files\n",
    "        p, p_std = bin_avrg.compute_mean(ts, ts_bin_map)   # from time-series to bin-averaged quantities\n",
    "        # clean up the time series data and apply the scada_ts filter\n",
    "        ts = restrict_to_ts(ts, scada_ts)\n",
    "    else:\n",
    "        p = bin_avrg.read_ba_file(file_name)\n",
    "    sim_ts.append(ts)\n",
    "    sim_P[isim] = p\n",
    "    sim_P_std[isim] = p_std\n",
    "    \n",
    "# where sim_P.loc['anh01'].loc['ANHA01'].loc['N'].loc['u'] provides the mean power for anh01 simulation at \n",
    "# turbine A01 for North sector in unstable conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation data\n",
    "To increase the data availability, a machine learning algorithm has been applied to recover data from turbines that are not working in nominal conditions from others that do. Then, the \"gap-filled\" observational data is loaded and the scada_ts filter applied to syncronize with the simulation data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    obs_ts = pd.read_csv('./observations/obs.csv', index_col = 'time') \n",
    "    obs_P, obs_P_std = bin_avrg.compute_mean(obs_ts, ts_bin_map)  \n",
    "    # clean up the time series data and apply the scada_ts filter\n",
    "    obs_ts = restrict_to_ts(obs_ts, scada_ts)\n",
    "    val_data = True\n",
    "except IOError:\n",
    "    print (\"No validation data available\")\n",
    "    val_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no validation data is available, do code to code comparison by selecting a reference simulation to compare against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sim = 0\n",
    "\n",
    "if val_data:\n",
    "    ref_P = obs_P\n",
    "    ref_P_std = obs_P_std\n",
    "else: \n",
    "    ref_P = sim_P[ref_sim]\n",
    "    ref_P_std = sim_P_std[ref_sim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute quantities of interest and metrics\n",
    "*Array efficiency* for a wind turbine is defined as:\n",
    "\n",
    "$$ \\eta_{i} = \\frac{P_i}{P(S_i)} $$\n",
    "\n",
    "and for the whole wind farm as: \n",
    "\n",
    "$$ \\eta = \\frac{\\sum_{i}P_i}{\\sum_{i}P(S_i)} $$\n",
    "\n",
    "where $P_i$ is the power of turbine $i$, observed or simulated, and $P(S_i)$ is the theoretical power from the manufaturer's power curve computed at the background (mesoscale) wind speed $S_i$ at each turbine position.  \n",
    "\n",
    "Performance is measured in terms of the BIAS:\n",
    "\n",
    "$$ BIAS = \\eta_{obs} - \\eta_{sim} $$ \n",
    "\n",
    "for each turbine and wind farm per bin and integrated for the whole wind distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the arrays\n",
    "sim_eta = bin_avrg.array_init(('sim', 'wd','zL'))\n",
    "bias = bin_avrg.array_init(('sim', 'wd','zL'))\n",
    "dif_std = bin_avrg.array_init(('sim', 'wd','zL'))\n",
    "bias_tot = bin_avrg.array_init(('sim',))\n",
    "mae = bin_avrg.array_init(('sim',))\n",
    "len_array = np.vectorize(len)\n",
    "bin_sizes = len_array(ts_bin_map)\n",
    "sum_bin_sizes = bin_sizes.sum()\n",
    "meso_P_sum = np.sum(meso_P,axis=0) \n",
    "\n",
    "#compute variables of interest\n",
    "ref_eta = np.sum(ref_P,axis=0) / meso_P_sum * 100 # axis=0 are turbines\n",
    "\n",
    "ref_dif_std = np.mean(ref_P_std - meso_P_std,axis=0)\n",
    "for isim in range(n_sim):\n",
    "    sim_eta[isim] = np.sum(sim_P[isim],axis=0) / meso_P_sum * 100\n",
    "    bias[isim] = ref_eta - sim_eta[isim]\n",
    "    if sim_P_std[isim] is not None:\n",
    "        dif_std[isim] = np.mean(sim_P_std[isim] - ref_P_std,axis=0)\n",
    "\n",
    "    bias_tot[isim] = (bias[isim]*bin_sizes).sum()/sum_bin_sizes\n",
    "    mae[isim] = (np.absolute(bias[isim])*bin_sizes).sum()/sum_bin_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heat maps of bin-averaged array efficiency and bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figcaption = \"**Fig 2. Heat map of array efficiency**\"\n",
    "#title = \"_eta[%]\"\n",
    "#bin_avrg.plot_heatmaps(sim_eta, sub_plt_size = (1.7,4),n_plot_cols = 6, \n",
    "#                       figcaption = figcaption, title=title)\n",
    "\n",
    "figcaption = \"**Fig 3. Heat map of array efficiency BIAS**\"\n",
    "title = \"_BIAS[%]\"\n",
    "bin_avrg.plot_heatmaps(bias, sub_plt_size = (1.7,4),n_plot_cols = 7, \n",
    "                       figcaption = figcaption, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate along wind direction to obtain the bias vs stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_zL = (np.sum(bias,axis=1)/len(WDbins)).to_pandas() # bias vs stability [%]\n",
    "ax = bias_zL.plot.barh(rot=0, grid=1, colormap = 'bwr', edgecolor = 'grey',\n",
    "                    title='Bias vs stability [%]');\n",
    "ax.set_yticklabels(sim_name);\n",
    "ax.set_ylabel('');\n",
    "ax.legend(bbox_to_anchor=(1.15, 1)); # try stacked=True in the barh options \n",
    "ax.set_xlim([-20,5]); # use this to leave outliers out\n",
    "\n",
    "#bias_zL # uncomment to show table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate along stability to obtain the bias vs wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_WD = (np.sum(bias,axis=2)/len(zLbins)).transpose().to_pandas() # bias vs wind direction [%] \n",
    "ax = bias_WD.plot(rot=0, grid=1, figsize = (12,4), \n",
    "                    title = 'Bias vs Wind Direction [%]')\n",
    "ax.legend(sim_name, bbox_to_anchor=(1, 1));\n",
    "ax.set_ylim([-30, 10]); # use this to leave outliers out\n",
    "\n",
    "#bias_WD # uncomment to show table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficiency and bias per wind turbine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_eta_wt = bin_avrg.array_init(('sim', 'wt','wd','zL'))\n",
    "bias_wt = bin_avrg.array_init(('sim', 'wt','wd','zL'))\n",
    "\n",
    "ref_eta_wt = ref_P / meso_P * 100\n",
    "ref_eta_std_wt = ref_P_std / meso_P * 100\n",
    "\n",
    "for isim in range(n_sim):\n",
    "    sim_eta_wt[isim] = sim_P[isim] / meso_P * 100\n",
    "    bias_wt[isim] = ref_eta_wt - sim_eta_wt[isim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a transect, for chosen bin and wind turbines list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transect: Choose bin (WD,zL), define list of turbines and plot profiles of array efficiency along the transect of turbines. \n",
    "#           Normalized by dividing with eta of the first turbine in the list\n",
    "#           Use error bars showind one std about the observed array efficiency (eta_obs_std)\n",
    "\n",
    "WDbin = 'NNW'\n",
    "zLbin = 'n'\n",
    "\n",
    "# F transect\n",
    "wt_list = ['ANHF'+\"{:0>2d}\".format(29-i) for i in range(7)] #from F29 to F23  \n",
    "wt_list = wt_list + ['ANHF'+\"{:0>2d}\".format(14-i) for i in range(14)] # from F14 to F01\n",
    "# A transect\n",
    "#wt_list = ['ANHA'+\"{:0>2d}\".format(31-i) for i in range(10)] #from A31 to A22  \n",
    "#wt_list = wt_list + ['ANHA'+\"{:0>2d}\".format(20-i) for i in range(20)] # from A20 to A01\n",
    "\n",
    "# for list of turbines and wd, 2D plot Value per distance in rotor diameter. \n",
    "data =   sim_eta_wt.loc[:,:,WDbin,zLbin].to_pandas()\n",
    "ref_data = ref_eta_wt.loc[:,WDbin,zLbin].to_pandas()\n",
    "ref_data_std = ref_eta_std_wt.loc[:,WDbin,zLbin].to_pandas()\n",
    "meso_data = meso_P.loc[:,WDbin,zLbin].to_pandas()\n",
    "\n",
    "ax,bx = plot_transect(data,ref_data,meso_data,wt_list,turbines,Drot,sim_name,WDbin,zLbin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sim_eta_wt.loc['anh05',:,'SSE','u'].to_pandas()\n",
    "plot_wf_layout(turbines['X coordinate'], turbines['Y coordinate'],data = data,vmin=40, vmax=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bias_wt.loc['anh05',:,'SSE','u'].to_pandas()\n",
    "plot_wf_layout(turbines['X coordinate'], turbines['Y coordinate'],data = data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
